{"cells":[{"cell_type":"code","execution_count":null,"id":"hybrid-corner","metadata":{"id":"hybrid-corner"},"outputs":[],"source":["pip install -U selenium"]},{"cell_type":"code","execution_count":null,"id":"accepted-society","metadata":{"scrolled":true,"id":"accepted-society"},"outputs":[],"source":["from datetime import datetime\n","import time\n","import csv\n","from selenium import webdriver\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.chrome.options import Options\n","from selenium.webdriver.common.action_chains import ActionChains\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from selenium.common.exceptions import StaleElementReferenceException\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# Function to scrape CNN articles based on specified parameters\n","def scrape_cnn_articles(stop_date, search_term, start_page):\n","    # Set up options for the Chrome WebDriver\n","    options = Options()\n","    options.headless = False  # Set to True if you want to run in headless mode (no browser window)\n","\n","    # Initialize the WebDriver\n","    driver = webdriver.Chrome(options=options)\n","\n","    # List to store scraped results\n","    results = []\n","\n","    # Convert stop_date string to datetime object for comparison\n","    stop_date_object = datetime.strptime(stop_date, '%b %d, %Y')\n","\n","    try:\n","        # Navigate to the CNN search page with specified parameters\n","        driver.get(f'https://edition.cnn.com/search?q={search_term}&from=0&size=10&page={start_page}&sort=newest&types=article&section=')\n","\n","        # Main scraping loop\n","        while True:\n","            # Wait until the articles are present on the page\n","            WebDriverWait(driver, 10).until(\n","                EC.presence_of_all_elements_located((By.CLASS_NAME, 'card'))\n","            )\n","\n","            # Parse the HTML content with BeautifulSoup\n","            soup = BeautifulSoup(driver.page_source, 'html.parser')\n","            # Find all articles on the page\n","            articles = soup.find_all('div', class_='card')\n","\n","            # Iterate through each article\n","            for article in articles:\n","                # Extract date information\n","                date_element = article.find('div', class_='container__date')\n","                date_string = date_element.get_text(strip=True) if date_element else 'Date not available'\n","                date_object = datetime.strptime(date_string, '%b %d, %Y')\n","\n","                # Extract headline information\n","                headline_element = article.find('span', class_='container__headline-text')\n","                headline = headline_element.get_text(strip=True) if headline_element else 'Headline not available'\n","\n","                # Extract link information\n","                link_element = article.find('a')\n","                link = link_element['href'] if link_element else 'Link not available'\n","\n","                # Add the result to the list\n","                results.append({\n","                    'Headline': headline,\n","                    'Link': link,\n","                    'Date': date_object\n","                })\n","\n","                # Check if the article date is before the stop_date\n","                if date_object < stop_date_object:\n","                    print(f'Stopping scraping as an article with date {date_string} has been reached.')\n","\n","                    # Write the scraped data to a CSV file\n","                    with open(f'{search_term}_scraped_data.csv', 'w', newline='', encoding='utf-8') as csv_file:\n","                        fieldnames = ['Headline', 'Link', 'Date']\n","                        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","                        writer.writeheader()\n","                        for result in results:\n","                            writer.writerow(result)\n","                    print(f'Scraped data has been saved to {search_term}_scraped_data.csv')\n","                    return results\n","\n","            # Try to find and click the next page button\n","            try:\n","                next_page_button = WebDriverWait(driver, 10).until(\n","                    EC.presence_of_element_located((By.CLASS_NAME, 'pagination-arrow-right'))\n","                )\n","\n","                # Scroll to the next page button and click it\n","                driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n","                time.sleep(7)  # Add a delay to ensure the page has loaded\n","                next_page_button.click()\n","\n","            except StaleElementReferenceException:\n","                # Handle StaleElementReferenceException and retry finding the next page button\n","                print('Stale element reference. Retrying to find the next page button.')\n","                continue\n","\n","    finally:\n","        # Quit the WebDriver when done\n","        driver.quit()\n","\n","# Example usage:\n","# scrape_cnn_articles('Jan 01, 2024', 'example_search', 1)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"hungarian-cabin","metadata":{"id":"hungarian-cabin","outputId":"84a5b8ec-c3e9-421a-ed7d-d622734ceff2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stopping scraping as an article with date Oct 06, 2023 has been reached.\n","Scraped data has been saved to Israel_scraped_data.csv\n"]}],"source":["#Israel\n","scraped_articles = scrape_cnn_articles('Oct 07, 2023', \"Israel\", \"1\")"]},{"cell_type":"code","execution_count":null,"id":"neural-delta","metadata":{"id":"neural-delta","outputId":"e550c31f-a5cc-43c2-832a-06cf2df1081a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stopping scraping as an article with date Oct 04, 2023 has been reached.\n","Scraped data has been saved to Palestine_scraped_data.csv\n"]}],"source":["#Palestine\n","scraped_articles = scrape_cnn_articles('Oct 07, 2023', \"Palestine\", \"1\")"]},{"cell_type":"code","execution_count":null,"id":"digital-austria","metadata":{"id":"digital-austria","outputId":"dcdb55fb-0d27-435e-d12b-8ddaf840226e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stopping scraping as an article with date Aug 22, 2023 has been reached.\n","Scraped data has been saved to Hamas_scraped_data.csv\n"]}],"source":["#Hamas\n","scraped_articles = scrape_cnn_articles('Oct 07, 2023', \"Hamas\", \"1\")"]},{"cell_type":"code","execution_count":null,"id":"piano-greece","metadata":{"scrolled":true,"id":"piano-greece","outputId":"dc8a604f-79d3-4ddf-b575-09e508ce8cc9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stopping scraping as an article with date Oct 06, 2023 has been reached.\n","Scraped data has been saved to Gaza_scraped_data.csv\n"]}],"source":["#Gaza\n","scraped_articles = scrape_cnn_articles('Oct 07, 2023', \"Gaza\", \"1\")"]},{"cell_type":"code","execution_count":null,"id":"transsexual-thumbnail","metadata":{"id":"transsexual-thumbnail","outputId":"637e43b2-f74e-46b7-d877-0f6df262d6cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stopping scraping as an article with date Oct 06, 2023 has been reached.\n","Scraped data has been saved to IDF_scraped_data.csv\n"]}],"source":["#IDF\n","scraped_articles = scrape_cnn_articles('Oct 07, 2023', \"IDF\", \"1\")"]},{"cell_type":"markdown","id":"refined-lying","metadata":{"id":"refined-lying"},"source":["Combining CSV files and filtering on date"]},{"cell_type":"code","execution_count":null,"id":"finished-grain","metadata":{"id":"finished-grain"},"outputs":[],"source":["csv_files = ['Gaza_scraped_data.csv', 'Hamas_scraped_data.csv', 'Israel_scraped_data.csv', 'Palestine_scraped_data.csv', 'IDF_scraped_data.csv']\n","\n","dfs = []\n","\n","for file in csv_files:\n","    df = pd.read_csv(file)\n","    dfs.append(df)\n","\n","combined_df = pd.concat(dfs, ignore_index=True)\n","combined_df.drop_duplicates(inplace=True)\n","combined_df.to_csv('israel_palestine_conflict.csv', index=False)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"atmospheric-section","metadata":{"id":"atmospheric-section"},"outputs":[],"source":["df = pd.read_csv('israel_palestine_conflict.csv')\n","\n","df['Date'] = pd.to_datetime(df['Date'])\n","df.set_index('Date', inplace=True)\n","\n","start_date = '2023-10-07'\n","end_date = '2023-12-07'\n","filtered_df = df.loc[start_date:end_date]\n","\n","filtered_df.reset_index(inplace=True)\n","\n","filtered_df.to_csv('israel_palestine_conflict.csv', index=False)\n"]},{"cell_type":"markdown","id":"heavy-local","metadata":{"id":"heavy-local"},"source":["RUSSO UKRAINIAN WAR"]},{"cell_type":"code","execution_count":null,"id":"applied-macro","metadata":{"scrolled":true,"id":"applied-macro","outputId":"53582c26-f204-4003-cc6f-eec359849742"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stopping scraping as an article with date Feb 23, 2022 has been reached.\n","Scraped data has been saved to Ukraine_scraped_data.csv\n"]}],"source":["#Ukraine\n","scraped_articles = scrape_cnn_articles('Feb 24, 2022', \"Ukraine\", \"207\")"]},{"cell_type":"code","execution_count":null,"id":"impossible-methodology","metadata":{"id":"impossible-methodology","outputId":"6a6c2806-968d-476d-c9c3-558b2e817fc1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stopping scraping as an article with date Feb 23, 2022 has been reached.\n","Scraped data has been saved to Russia_scraped_data.csv\n"]}],"source":["#Russia\n","scraped_articles = scrape_cnn_articles('Feb 24, 2022', \"Russia\", \"176\")"]},{"cell_type":"code","execution_count":null,"id":"western-torture","metadata":{"id":"western-torture","outputId":"34d6d442-392e-4674-f3ad-99f50f3af9e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stale element reference. Retrying to find the next page button.\n","Stopping scraping as an article with date Feb 23, 2022 has been reached.\n","Scraped data has been saved to Putin_scraped_data.csv\n"]}],"source":["#Putin\n","scraped_articles = scrape_cnn_articles('Feb 24, 2022', \"Putin\", \"181\")"]},{"cell_type":"code","execution_count":null,"id":"reserved-profile","metadata":{"id":"reserved-profile","outputId":"d479f7d3-c846-46ea-8e24-3694106d2c54"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stopping scraping as an article with date Feb 19, 2022 has been reached.\n","Scraped data has been saved to Zelensky_scraped_data.csv\n"]}],"source":["#Zelensky\n","scraped_articles = scrape_cnn_articles('Feb 24, 2022', \"Zelensky\", \"14\")"]},{"cell_type":"code","execution_count":null,"id":"usual-inclusion","metadata":{"id":"usual-inclusion"},"outputs":[],"source":["csv_files = ['Russia_scraped_data.csv', 'Zelensky_scraped_data.csv', 'Ukraine_scraped_data.csv', 'Putin_scraped_data.csv']\n","\n","# List to store DataFrames read from CSV files\n","dfs = []\n","\n","# Loop through each CSV file and read it into a DataFrame\n","for file in csv_files:\n","    # Read CSV file into a DataFrame\n","    df = pd.read_csv(file)\n","\n","    # Append the DataFrame to the list\n","    dfs.append(df)\n","\n","# Combine all DataFrames in the list into a single DataFrame\n","combined_df = pd.concat(dfs, ignore_index=True)\n","\n","# Drop duplicate rows in the combined DataFrame\n","combined_df.drop_duplicates(inplace=True)\n","\n","# Save the combined and deduplicated DataFrame to a new CSV file\n","combined_df.to_csv('russia_ukraine_conflict.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"average-ticket","metadata":{"id":"average-ticket"},"outputs":[],"source":["df = pd.read_csv('russia_ukraine_conflict.csv')\n","\n","#filter on date\n","df['Date'] = pd.to_datetime(df['Date'])\n","df.set_index('Date', inplace=True)\n","\n","start_date = '2022-02-24'\n","end_date = '2022-04-24'\n","filtered_df = df.loc[start_date:end_date]\n","\n","filtered_df.reset_index(inplace=True)\n","\n","filtered_df.to_csv('russia_ukraine_conflict.csv', index=False)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}